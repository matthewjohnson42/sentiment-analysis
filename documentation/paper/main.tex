\documentclass[letterpaper, 10 pt, conference]{ieeeconf}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{amssymb}
\IEEEoverridecommandlockouts
\overrideIEEEmargins
\title{A Study of Ontology Supported Sentiment Analysis*}
\author{Matthew Johnson \thanks{*This paper is a draft and intended to be subject to extensive revision}}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
The purpose of this paper is to provide a review of the literature relevant to a discussion of ontologies as a method for formally describing concepts and improving the digital exchange of information, and of sentiment analysis as performed computationally. The paper will discuss the intersection between the two as it exists in a subset of the current body of published scholarly articles, and briefly conjecture on the nature of representation and the difficulties that this puts forward to any attempt to discuss that which emerges from it.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}
Sentiment analysis is an area of study that hopes to describe the sentiment, or feeling, embodied by a given portion of text. It is a subset of natural language processing, and utilizes many of the ideas core to the analysis of natural languages. The tasks of sentiment analysis have traditionally been of interest to psychology, linguistics, and more recently to the information and computational sciences. To perform an analysis of sentiment in textual data is no simple task. No single approach has been found that provides definitive assessment of the sentiment in a given text. It is by no means a solved problem, and there are many open questions relevant to the development of a robust methodology for the performance of sentiment analysis. For example, how one might best characterize sentiment is a question that proves to be of some difficulty and is a question that must be posed in order to do sentiment analysis. It is not as simple a characterization as is the characterization of the measure of a pile of unprocessed cereal grains, where a weight and volume occupied by the whole might be taken and represented as distinct quantities. It is very difficult to describe sentiment as numerical quantity, the method of representation that finds itself most amenable to computation by discrete processes.

Even when a mildly adequate method of numerical representation has been attained, there remains the difficulty of comparing different sentiments as embodied by the text from which a numerical representation has been derived. For example, after having identified several base orientations or modes of feeling and attributing certain magnitudes to each of those bases for a given segment of text, there is the next obstacle of comparing those representations in ways that respects the whole of the representation instead of treating only of each of the individual magnitudes. The fear embodied by a text providing a personal account of drowning is likely one that differs for most readers and writers from the fear embodied in a text providing a personal account of the delivery of a public address. This respect is at the core of most of the successful methods for performing sentiment analysis. Comparison of magnitudes simply does not do the potential difference of emotive content justice.

There are many approaches to performing sentiment analysis, but for the purposes of this paper we will focus on sentiment analysis as performed computationally. We will aspire to include in the elucidation of this area of study those ideas advanced in the corpus of psychological and linguistic publications that might be of assistance in providing reinforcement to or expansion of existing computational methods in sentiment analysis. Section II of the paper will describe the existing research that has been done in computational sentiment analysis and the methods devised in that research. Section III will go on to discuss the emergence of ontologies as a method for conveying data in the information sciences in a regularized, formal, and well defined way. Section IV will describe how such ontologies have been leveraged to provide more effective sentiment analysis of textual data. Section V will provide some closing remarks on the intersection of sentiment analysis and ontologies as described in the information and computational sciences.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{COMPUTATIONAL SENTIMENT ANALYSIS}
Computational sentiment analysis is the process of extracting through consistent and replicable methods the sentiment of a given portion of textual data. It is a process that hopes to allow the user of such a process to be able to ascertain without having read a text the opinions and sentiments present in that text. Both the terms sentiment analysis and opinion mining are used to refer to this process, though in some cases opinion mining is considered to be a subprocess of sentiment analysis \textcolor{gray}{\cite{PangLee,RaviRavi}}. For this reason we refer to the process described in this section of this paper by the term sentiment analysis.

The process of sentiment analysis can be divided into 4 subprocesses: pre-processing, sentiment orientation, polarity classification, and sentiment attribution. The core subprocess is generally considered to be that of polarity classification \textcolor{gray}{\cite{PangLee,RaviRavi}}. These subprocesses do not necessarily occur in this order, and some of the subprocesses might be combined and their distinctions blurred in some applications of sentiment analysis. Some approaches to the classification of text into different sentiment categories might not use any of the methods described in these 4 subprocesses at all. The description of sentiment analysis in this paper is by no means a description that is complete. As mentioned in the introduction, the problem of sentiment analysis is one that is difficult to define and as such lacks a clear and definitively correct solution. There are many different ways of performing sentiment analysis, and these subprocesses were chosen for their ability to describe many, but not all, of the methods and ideas used in computational sentiment analysis. For the purposes of the advancement of the paper, we will assume that a program that performs a sentiment analysis generally treats each of the subprocess as distinct and moves through them sequentially. The paper will describe these four subprocesses and then continue on to make some brief and general remarks about sentiment analysis.

\subsection{Pre-processing} Pre-processing methods are methods that are used in the course of a sentiment analysis to help remove erroneous information from a text and to help provide structure to the text being analyzed. A common pre-processing method is the classification of portions of the document into the categories of subjective and non-subjective. Subjectivity is often defined in such a textual analysis to be the textual representation of a private state which is unverifiable by an objective, outside viewer \textcolor{gray}{(\cite{PangLee}, page 9)}. Such a classification assumes that by identifying those portions of a text that are subjective, one can then retain only those portions and as a result of this attain a more accurate classification of sentiment. A common method of performing subjectivity analysis is to retain those portions of text that have adjectives, as it has been observed that there is a correlation between the use of adjectives in and the subjectivity of a sentence \textcolor{gray}{(\cite{PangLee}, page 34)}. Another method of performing subjectivity analysis is to identify which portions of a text contain hapax legomena, words that occur only once in the whole of a text \textcolor{gray}{(\cite{PangLee}, page 33)}. Hapax legomena have also been observed as frequently coinciding with sentences that are classified as being subjective. Subjectivity classification performed in ways such as these has been identified as a pre-process that greatly enhances the performance of sentiment analyses, and is considered by some to be a more difficult problem than the polarity classification mentioned later in this paper \textcolor{gray}{(\cite{PangLee}, page 28)}.

Another common set of pre-processes include methods that create structure for textual data, be that structure an unordered set of words, an ordered set of words, a set of groupings of words, or tagging of the words with their associated parts of speech and grouping the words into syntax or parse trees based on the part of speech tagging. Most of these structures are ones that retain a respect for the difficulties of clearly defining the structure of language in general as mentioned by Chomsky \textcolor{gray}{\cite{Chomsky}}. The importance of a respect for the complexity of language that Chomsky frequently puts forward to statistians, information scientists, and computer scientists is explicitly acknowledged in the work of Cambria et al \textcolor{gray}{\cite{CambriaPoria}}. An unordered set of words is often referred to as a bag of words, where the assumption is that sentiment pertains only to the frequency of occurrence or the presence of the words of a portion of text. Approaches that assume the importance of a word's presence as opposed to its frequency or connection to other portions of a text have been used to positive effect in some limited cases \textcolor{gray}{(\cite{PangLee}, page 33)}.

An ordered set of words or a set of groupings of words is sometimes referred to as a feature vector or word vector, and assumes that the relation of words in a document is relevant to the performance of an analysis of sentiment. In some cases, an ordered or grouped set of words may incorporate part of speech tagging as part of their definition. These parts of speech include adjectives, nouns, verbs, and others, which are then stored along side the word in the feature vector. Part of speech tagging might also be used in some cases to create syntax trees, where the words of a document are related to each other through the grammatical structure of the language of the text. This is a more traditional process that is associated with natural language processing, and has been thoroughly explored in works like that of WordNet \textcolor{gray}{\cite{WordNet}}.

Other pre-processes that are used draw heavily from the techniques of semantic analysis. One very simple technique that is used is the removal of very common words that don't add any additional semantic value to a sentence, words such as "the" "he" "be" and other similar words. These words are referred to as stop words \textcolor{gray}{\cite{Manning}}. Another technique that draws from semantic analysis is the designation of words as being modified by negations. For example the statements "I enjoy swimming" and "I don't enjoy swimming" are the same sentence separated by the negation present in the word "don't". The identification of the presence of these negations can allow an analysis of sentiment to change the meaning of the word that is negated, should the word have any sentiment value. There are other challenges present in the pre-processing of text for sentiment analysis that remain partially unaddressed such as disambiguation of vague statements and the detection of complex, non-literal linguistic expression such as that of sarcasm in text \textcolor{gray}{\cite{RaviRavi}}.

\subsection{Sentiment orientation} Sentiment orientation is the process of determining which sentiments can be said to be in the textual data as provided by the pre-processing. This is generally speaking the definition of the characterization of sentiment as a measure, the difficulties of which we briefly mentioned in the introduction. In computational sentiment analysis, the definition of sentiment can be as simple as stating that the classification to be performed is to be done on the basis of the text acquiring the label "is positive" or not acquiring the label. A slightly more complex definition would be to classify sentiment into the categories "is positive" and "is negative", or slightly more complex still the description of sentiment as being positive, neutral, negative. A more detailed classification might consider the positive, neutral, and negative sentiments of a portion of text to be on a continuous spectrum, with the poles of the spectrum representing the prevalence of that given sentimental orientation. One such method of classification is that used by SentiWordNet, where the sentiment of a word is measured as a distributed between positive, objective, and negative sentiment \textcolor{gray}{\cite{Esuli,Baccianella}}. In these characterizations of sentiment as being only polar, existing only on a scale of negative to positive, the process of determining sentiment orientation is implicit in the definition of the problem of sentiment analysis as opposed to being explicitly determined by a distinct subprocess of sentiment analysis. In these characterizations, the subprocess referred to in this paper as sentiment orientation is collapsed into the quantification stage of sentiment analysis referred to in this paper as polarity classification.

There appear to be relatively fewer methods of performing computational sentiment analysis that consider an orienting of sentiment that is more complex than this spectral or polar classification, with most methods considering the task of sentiment analysis to be only the classification of the polarity of sentiment. One potential method of orienting sentiment that is more complex than such a classification of positive and negative would be to describe the expression of sentiment as falling into different affective categories, then describing the prevalence of each of these categories in a given segment of text. Pang and Lee make mention of orienting sentiment relative to the six affect typifications of anger, disgust, fear, happiness, sadness, and surprise \textcolor{gray}{(\cite{PangLee}, page 31)}. WordNet-Affect \textcolor{gray}{\cite{Strapparava}} and SentiFul \textcolor{gray}{\cite{Neviarouskaya}} are lexicons that correlate words with multiple affects in such a manner, though in the case of SentiFul and in many uses of WordNet-Affect the data that is taken from these lexicons is only the positive or negative sentiment scores of the words of the lexicon computed from these affects. SenticNet is another resource that is similar to a lexicon that makes use of multiple affects, but it too generally considers its output in terms of a dipole sentiment classification \textcolor{gray}{\cite{CambriaSpeer}}. ConceptNet also allows for its contents to be described according to six different affective categories, but does not provide any method of sentiment analysis beyond the correlation of individual concepts with several basic affective categories and simple aggregation of these correlations across the sum of a text\textcolor{gray}{\cite{Liu}}.

In cases where a more complex process of a sentiment orientation exists, it is important to note that there are some difficulties in strictly defining what affects are relevant in such a process or even what affects can be said to exist. For example, Strapparava and Valitutti identify the word anger as an emotion, the word animosity as a mood, and the word confusion as a cognitive state to all have some bearing upon the sentiment of a portion of text, yet these words are not able to be typified in the same way as described by Pang and Lee \textcolor{gray}{\cite{Strapparava}}. Further, Strappavara and Valitutti cite that the psychological literature they found as relevant to an analysis of emotion agreed at the time to only the two features of arousal and valence which together lack the ability to describe more nuanced sentiments. Such sentiments might be such as those of a peaceful contentedness that one might experience walking through a still forest thick with fog, the sound of a small stream in the distance behind you, or the sort of all-encompassing panic that might amount from a sudden realization that your clothes have been positioned in such a way so as to reveal more than typically is considered socially acceptable. While there does exist literature that provides a more robust description of human emotion \textcolor{gray}{\cite{CambriaSpeer}}, Strappavara and Valitutti are astute in their consideration of human emotion as forming a difficult to analyze and complex structure. Their claim to the fairly simple methods of affective categorization is mirrored in the definition of only two affective categories in ConceptNet 2.0 \textcolor{gray}{\cite{Liu}}. Balahur et al also describe the difficulty involved with the orienting of sentiment in text, noting that there are many theories of psychology that have explanatory power in regards to emotion and affect, and that many methods in sentiment analysis focus on only appraisal theory \textcolor{gray}{\cite{Balahur}}. They note that while there is no current consensus on the most effective, descriptive, or encompassing methods of explaining and typifying affect and emotion, NLP must begin its assessment of sentiment with some explanatory theory either explicit or implicit in its choice of methodology. This difficulty in determining the orientation of sentiment is perhaps provides insight into why classifications of sentiment that consider only positive or negative sentiment are as prevalent as they are in a computational analysis of sentiment.

A method of orienting sentiment that is more complex than any of those mentioned previously might be an analysis that considered the transition of passages of a text from one distribution of sentimental categories to another as the text progresses. In such a case the definition of progress in a text could be defined in various ways. Consider progress being a change between topics versus progress being the beginning of another sentence, or the progress between semantic structures such as word phrases or clauses. An expansion of the existing methods of computational sentiment analysis to include more complex characterizations such as one inclusive of the temporal dimension of emotion would likely draw heavily on more diverse methods of processing natural language such as those found in psychology and linguistics. Balahur et al made an attempt at creating such a method of orienting sentiment in EmotiNet, where portions of text containing noun-verb-noun clauses were interconnected on the assumption that many of these clauses could be stratified temporally and can be assessed as having affective content \textcolor{gray}{\cite{Balahur}}.

\subsection{Polarity classification} 
Polarity classification is the process of assigning numerical measures to a given portion of text for each the possible labels that were identified in the sentiment orientation subprocess. This may be as simple as a binary classification or as detailed as a continuous valuation on the interval $[-5,5] \in \mathbb{R}$. Broadly speaking this process may be broken down into two general approaches: unsupervised approaches and supervised approaches. In some cases, unsupervised approaches are referred to as lexicon based approaches and supervised approaches are referred to as machine-learning based approaches \textcolor{gray}{\cite{RaviRavi}}.

\subsubsection{Unsupervised approaches}
Unsupervised approaches are generally those that concern themselves with the correlation of previously known measures of sentiment for individual words to the words of a given portion of text. The body of knowledge that is drawn on in this process is often referred to as a lexicon. A lexicon is a dictionary of words with correlated meanings. In the case of sentiment lexicons or lexicons used towards the end of sentiment analysis the meaning of a word is the positive or negative sentiment attached to a given word. For example "enjoyable" might be a word in a lexicon that has a positive sentiment value whereas "terrifying" might be a word in a lexicon that has a negative sentiment value.

Once the words of a portion of text have been compared with a sentiment lexicon, the sum of the values assigned to each of the words in that portion of text may be taken and used as a very rough and general determination of the sentiment for that portion of text. There are also more complex methods that segment an input text in certain ways which we will describe further in the section of the paper titled sentiment attribution. In general the premise of unsupervised approaches is that they can utilize existing knowledge about the sentiments expressed in language as embodied by a lexicon in order to classify portions of text that have not been labeled by a human with a corresponding characterization of the sentiment in that portion of text. The classification of polarity in these cases does not rely on labeled data sets and so is considered to be unsupervised in the language of artificial intelligence and machine learning.

Some unsupervised approaches rely on lexicons that are already developed. The utilization of existing lexicons in sentiment analysis can be fairly simple, though there is some variance in the type of labeling that sentiment analysis draws from different lexicons as mentioned in the previous section on sentiment orientation. Some lexicons such as that of the General Inquirer contain two categories that are utilized for sentiment analysis, one for words that have a positive sentiment and one for words that have a negative sentiment \textcolor{gray}{\cite{Buvac}}. These categories are then predicated or not predicated of a given word. Other lexicons attempt to describe the sentiment value of a word with more than two values, the sentiment value sitting somewhere in a range of possible values of varying negative and positive intensity \textcolor{gray}{(\cite{RaviRavi}, page 20)}. As noted previously, most of the uses of lexicons in sentiment analysis restrict themselves to the assignment of positive or negative values for words, though there are lexicons that contain many more dimensions than those of positive and negative. General Inquirer, for example, contains some 144 categories into which words may be classified although only the two mentioned above are relevant to sentiment analysis.

There are a great many lexical resources that have been developed for the purposes of sentiment analysis though not all of these lexicons were developed in a manner that was unsupervised. Some lexicons have relied on supervised machine learning techniques for their development. Several lexicons that we may speak of here are WordNet-Affect, SentiWordNet, and SentiFul. WordNet-Affect is an expansion of the lexicon of words, WordNet \textcolor{gray}{\cite{Strapparava,WordNet}}. WordNet is a lexicon that encompasses the whole of the English language, and forms in a certain sense an extensive digital dictionary for the English language. The entries in WordNet are groupings of synonyms, referred to as synsets (synonym sets). Each of these synsets has what is referred to as a gloss, which is a brief description or definition of the words of the synset. Synsets also have senses attributed to each of the words, for example the word happy might be considered to have one meaning or sense when it is taken to describe the mood of a person as manifest in their smile and another when it is used to describe a state of affairs as being amenable. Each sense or usage of a word exists in a distinct synset describing the sense that is related to that specific usage of that specific word. Synsets in WordNet are related to each other with relational tags which include tags such as "antonymy", "similarity", and "also-see". WordNet-Affect is an expansion of WordNet that moves to include in each synset a labeling of the affect categories of emotion, cognitive state, trait, behavior, attitude, and feeling. WordNet-Affect was created by manually applying these affective labels to a selection of synsets, and those labels were then propagated to other synsets that had certain relations to the initial set of labeled synsets.

SentiWordNet builds on WordNet in a way that is similar to WordNet-Affect \textcolor{gray}{\cite{Esuli,Baccianella}}. It too considers the relations of different synsets, but instead of providing a tagging of the synsets with different labels, SentiWordNet provides each of the synsets of WordNet with scores for positive, negative, and objective sentiment. Each score may be any of $0, \frac{1}{8}, \frac{2}{8}, \frac{3}{8}, \frac{4}{8}, \frac{5}{8}, \frac{6}{8}, \frac{7}{8}, 1$ with the sum of the scores for positive, negative, and objective summing to a total of $1$. A small set of synsets were labeled as being paradigmatically positive, paradigmatically negative, or entirely objective. This set of synsets was expanded using the same relational tags present in WordNet as were used by WordNet-Affect, the labels of the original synsets being transferred to the related synsets in a way consistent with the definition of the relation ("also-see" provided the same values to related synset, "antonymy" provided the opposite values). This process of propagating the values of the initial set of synsets was done for synsets that were of a distance of $0, 2, 4, 6$ from any of the initial synsets (distance being the number of relations passed through to arrive at a new synset). These four different sets of labeled synsets were then used as input to two statistical classifiers, SVM and Rocchio. The inputs to the classifiers were the glosses of the synsets as a bag of words along with the sentiment scores of each synset. This created a total of $8$ binary classifiers, which were then each applied to all synsets in WordNet. The score for each synset was assigned as the average score of each of the $8$ classifiers. These synsets, now with scores for positive, negative, and objective sentiment, were then put through a random walk algorithm that attempted to find convergence on these scores when the algorithm stepped through WordNet by considering relations between synsets as the presence of one of the words of a synset in the gloss text of another synset.

SentiFul is similar to both WordNet-Affect and SentiWordNet \textcolor{gray}{\cite{Neviarouskaya}}. SentiFul draws initially on the Affect database which describes some $2438$ terms with the nine different emotions of anger, disgust, fear, guilt, interest, joy, sadness, shame, and joy. Each of the emotions for a given term are labeled with a corresponding intensity from $0$ to $1$, with those emotions that were labeled as a $0$ being left out from the description of the term. Polarities were then determined for each term from these labels with interest, joy, and surprise being considered as contributing to positive sentiment and anger, disgust, fear, guilt, sadness, and shame being considered as contributing to negative sentiment. Each term was given a positive and a negative polarity score from $0$ to $1$ and a weight for both the positive and negative score. The weights correspond to the ratio of the positive or negative emotions attributed to a term and the total emotions attributed to a term (eg: the term pensively has labels 'sadness:0.2' and 'interest:0.1', and so has a positive score of $0.1$,  positive weight of $0.5$, a negative score of $0.2$, and a negative weight of $0.5$). These ratings were propagated to all terms that shared a synset with existing terms, then all nouns that WordNet denoted as antonyms for existing terms, then all terms WordNet lists as hypernyms for existing terms, then all words that use one of the existing terms as a prefix or suffix, then common combinations of the existing terms. These terms then had a select few denoted as being modal words, which the authors consider to bear considerably greater weight in the determination of the significance of the sentiment expressed.

\subsubsection{Supervised approaches}
Supervised approaches stand in contrast to unsupervised approaches in that they utilize sets of textual data that have been annotated by a human with the varying characterizations of sentiment, but generally don't utilize large bodies of general human knowledge like lexica. The most abundant source of information that is labeled in this way is the information of online consumer reviews that are accompanied by a score. Movie reviews and ratings from IMDb have been used to perform studies in sentiment analysis, along with consumer reviews for cell phones and cars. In each of these cases we describe here the output of an analysis of sentiment is already known, and machine learning techniques that match inputs to their known categorizations can be leveraged for the identification of sentiment in text. The process is one in which statistical models are made that allow for this process of inference to take place. Some of the statistical models/machine learning techniques that have been utilized towards this end are n-gram models, Support Vector Machines, Naive Bayes Classifiers, Neural Networks, Markov blanket classifiers, Maximum entropy classifiers, linear regression models, and Latent Drichilet Allocation \textcolor{gray}{\cite{RaviRavi}}.

One particular method of performing a supervised analysis of the sentiment of a text is the n-gram. N-grams are pairings of n words, where the probability of the occurrence of a word is assumed to be determined by the preceding $n-1$ words \textcolor{gray}{\cite{Zhou}}. A set of probabilities may be obtained from a training corpus by considering each distinct sequence of $n-1$ words in the training corpus and determining what words follow that sequence and what their frequency of occurrence is relative to all words that follow that sequence in the training corpus. This relative frequency of occurrence is the probability of the occurrence of a word given the previous $n-1$ words. In sentiment analysis, the modeling of an n-gram is performed for each of the subsets of a training corpus that have a shared label. For example, if a polarity classification is being performed that considers only text that has positive or negative sentiment, then one set of n-gram probabilities would be created for both positive and negative sentiment. These would represent the probability of occurrence of words in texts known to have positive sentiment, and in texts known to have negative sentiment. In order to predict if a given text is either negative or positive, the probability of the text in whole is considered as the probability of the sequence of words that comprises the text with respect to the negative or positive n-gram model. The probability that a given sequence of words is positive would then be the product of the probability of occurrence of each of the n-grams of a given portion of text with respect to the positive set of n-gram probabilities. The probability that a given sequence of words is negative is computed also as the product of the probability of all n-grams in a text but with respect to the negative set of n-gram probabilities. More often than not either 1-grams or 2-grams, referred to as unigrams and bigrams respectively, are the type of n-gram used in sentiment analysis \textcolor{gray}{\cite{PangLee,RaviRavi,Zhou}}. This supervised model of sentiment analysis is, along with the Support Vector Machine, one that has consistently provided good predictive capability.

One of the more interesting approaches to a supervised polarity classification is the use of Latent Dirichlet Allocation \textcolor{gray}{\cite{Blei}}. Latent Dirichlet Allocation is a process that draws heavily on the literature pertaining to information retrieval, a natural language processing task concerned with the classification of documents by their topics, among other things. LDA operates on the assumption that there are meaningful patterns in documents that exist and are indicative of the themes or topics of the document. These topics are represented as probability distributions over words, much in the same way that Griffiths et al suggest \textcolor{gray}{\cite{Griffiths}}. When taken as a probability distribution over words, a document is represented by the number of occurrences of a each of the distinct words of the document relative to the total number of words in the document. This is referred to as a topic model of language. LDA extends this to describe documents as consisting of a blend of different topics. In order to do this, LDA needs to be able to specify the topics of a given corpus of text prior to the representation of the documents as mixtures of topics. LDA creates such a representation by initializing an effectively random set of probability distributions over the vocabulary of the corpus and then forming these multiple probability distributions to approximate each of the documents in the corpus. The process in which LDA performs this task is referred to as a variational EM procedure. Once the topics have been defined, a Dirichlet may be constructed that defines a given document. Each document is assessed as having a certain distribution of topics, the process of this assessment being an approximation process. These are a probability distribution over a probability distribution over words and can be considered to be representations of a document. One value for each topic is associated with each document. The end result of LDA is that documents can be decomposed into a fixed length set of real valued variables, these sets being referred to as Dirichlets. Such Dirichlets could be seen as similar to the gists that are mentioned in Griffiths et al \textcolor{gray}{\cite{Griffiths}}. The authors suggest that these decompositions can then be used to train Support Vector Machines or other statistical classifiers for the purpose of document classification. Ravi and Ravi cite several authors as having utilized LDA in this manner.

\subsection{Sentiment attribution}
The sentiment attribution subprocess is the process of determining what a set of polarity classifications refers to. It is the process of determining the subject of the sentiment, that which the sentiment is attributed to, that which the sentiment describes. In some cases, this process is the attribution of sentiment from consumer reviews to a product. The process of attribution of sentiment to reviews is sometimes referred to as opinion mining, this being the reason for our choice of the term sentiment analysis for this paper \textcolor{gray}{(\cite{PangLee}, page 57)}. In other cases, it is an attribution of sentiment to an individual or political party. Sometimes in these cases sentiment is attributed to the interlocutors of a conversation, with the sentiment being used to generalize the political content of a given portion of text and the content being considered in part as relations between documents \textcolor{gray}{\cite{PangLee}, page 47}. In other cases still, the sentiment is attributed to the document that has been analyzed, and in some cases the topic of the document that has been analyzed \textcolor{gray}{(\cite{PangLee}, page 37)}.

Sentiment attribution can be done at differing levels of granularity. One level at which sentiment attribution takes place is at the document level, where the whole of a given text is assigned a sentiment score. This is the coarsest of sentiment attributions, and is utilized to positive effect in the analysis of consumer reviews. A less coarse level of sentiment attribution is sentiment attribution performed at the sentence or paragraph level, though in these cases such a finer grained sentiment attribution is commonly used toward the end of a sentiment attribution performed at a document level. Another granularity of sentiment attribution is sentiment attribution which considers different aspects of a document, where the aspects of the document may be described across multiple sentences and different paragraphs. These aspects may be the features of a given consumer product, or may be the different aspects of a movie. Such an approach may also hope to encode in the aspects of a document the semantic or contextual features of that aspect. It is towards this end of sentiment attribution at a finer and more precise grain that ontologies are applied.

\subsection{Remarks}
It is worth while to keep in mind when considering computational sentiment analysis that there are many approaches to performing sentiment analysis and that an attempt to broadly generalize all approaches that have been taken is likely to fall short of describing all approaches. Unsupervised and supervised methods of performing natural language processing tasks like polarity classification are general categories and many of the approaches that will be described in section IV of this paper will make use of a blend of both methods. The terminology used here should not be considered to be definitive or even clearly defined. It is also worth the effort to emphasize exactly how simple any method of sentiment analysis is in comparison to the processes used in the course human interaction to infer the sentiment of a bit of language, written or otherwise. These approaches as described n this section cannot hope to begin to compare to the processes that occur in a human mind when reading a text, processes like conceptual recall, associative memory both in observation and formation, and the many imagined meanings that contribute to and compose the vibrancy of linguistically inclined thought.

\section{INFORMATIC ONTOLOGIES}
Ontologies as described in this paper differ from the traditional philosophic definition of the term, wherein questions of ontology pertain to the mode of being of the philosophical subject, the human being in the world. Here ontology is used as a term to describe the mode of being of a rational agent, a program that operates on data in a way that might be described as rational. The information of these ontologies forms the universe of discourse for a rational agent. An ontology so described forms the limits of existence for a rational agent, and hence the term is used with respect to rational agents in the same manner it is used with respect to humans. Ontologies for rational agents are markedly different in the literature from ontologies for humans, in no small part a result of the human mind being able to stand apart from a rational agent's mode of existence to be able to see it more clearly. Whereas an ontology of the human mind tends to find itself immersed in a discussion of matters immaterial, ontologies in the literature of informational and computational science aspire to be formally and clearly defined. They are described in the literature as being ways of formalizing concepts, of providing structure to information in a way that allows the information to be easily transferred between programs. To mark this distinction from philosophical ontologies, we use the term informatic ontology. Informatic ontologies can be specific to a given domain such as the domain of movie reviews or more general such as the ontology of ConceptNet, which hopes to describe as much as is possible for an informatic ontology focused on the words of a language. We will begin our discussion of informatic ontologies by referring to the definition that has been provided by Gruber.

\subsection{Gruber's definition.}
Thomas Gruber's 1993 paper "Toward Principles for the Design of Ontologies Used for Knowledge Sharing" is heavily cited and might be considered to be a landmark paper in the discussion of ontologies as they exist for the information and computational sciences \textcolor{gray}{\cite{Gruber}}. Gruber defines an ontology as "an explicit specification of a conceptualization". He describes ontologies as being that which "defines the vocabulary with which queries and assertions are exchanged among [rational] agents". They are the formal definition of the concepts with which rational agents act. Ontologies are the structure that enables rational agents to communicate while not always having the same or even similar vocabularies.

Gruber specifies several criteria by which we can grade the efficacy of an ontology. His suggestion is that we view informatic ontology development in the same way that we view software development; from the perspective of an engineer. The first criteria is clarity, by which Gruber seems to mean that the definitions of the concepts of an ontology should be as free from ambiguity an unnecessary complexity as is possible. The mark of clarity is a complete definition, wherein a predicate of a concept is defined by those conditions that are both necessary and sufficient for that predicate, allowing a definition that includes exactly those things that embody a concept and nothing more. It is a measure of precision in this way.

The second criteria Gruber mentions is that of coherence. By this Gruber is referring to a system that is logically coherent, wherein any of the statements made in that system do not contradict any other statements made in that system. This coherency is extended to those portions of a conceptualization that cannot be made explicit in logical form, though the method for this Gruber seems to be less clear on. Further, anything that is entailed by any of the statements made in the ontology must also be consistent with the whole of the ontology. Coherence here is agreement of the parts with the whole.

The third criteria of which Gruber speaks is that of extensibility. Extensibility is the ability of an ontology to grow, to have more concepts added to it. It is in this way a sort of requirement that an ontology not be static, that an ontology be morphological in the biological, living, and moving sense of the word. There should never be a limit to the number of concepts that an ontology communicates, and the implementation of the ontology should be such that the structure defined by the ontology cannot be exhausted. Any concept that is added to an ontology should also be able to ensure that its insertion into the ontology retains the principle of coherence, so that a new concept does not require that concepts already existing in the ontology be redefined.

The fourth criteria is that an ontology should have minimal encoding bias. In this Gruber seems to speak of the more general principle of ontologies, though here the principle is instead applied to the means by which the ontology is communicated. An example of this might be the definition of the derivative using Leibniz notation versus Lagrange notation in calculus. Although Gruber does not specify which representation is to be chosen in such a situation, the principle being communicated seems to be that when presented with two choices, the more generic of the two should always be chosen.

The fifth and final criteria by which we might gauge an ontology is minimal ontological commitment. In this Gruber seems to be stating again that generality is to be preferred in the construction of ontologies. Here the claim appears to be that a specification of an ontology should require of its users as few concepts as possible. The extensibility of an ontology is to be left to those programs and people that make use of the ontology, and the ontology should be as compact as possible.

Together, these five criteria are what Gruber suggests form a ontology as such a thing might be considered in the informational and computational sciences. The overall principle seems to be finding the minimal description of the structure of knowledge necessary for a given task, and ensuring that the principle of bare bones description also apply to the knowledge itself. The goal of ontologies is the sharing of knowledge and towards this end there have been several attempts at creating ontologies to help us describe the world in such general and extensible ways.

\subsection{Implementations of ontologies.}
Using the description provided by Gruber, WordNet can be considered an ontology \textcolor{gray}{\cite{WordNet}}. It forms the structure for the relation of different words of the English language, and when the words of English are clustered into sets of synonyms as they are in WordNet, they can be considered to form good but rough approximations of formal concepts \textcolor{gray}{\cite{Strapparava}}. WordNet in its whole does not meet many of the criteria that Gruber specifies, but when taken as a logical structure WordNet does indeed act very effectively as an ontology for the domain of the English language. The ontological component might be considered to be the general form of the synset, its various descriptive components along with the words that are synonymous. The grouping of synonyms, the glosses associated with those groupings, and the relations between synsets might be considered to be a good ontology that has proven itself to be extensible, to maintain a certain coherence and clarity, and to avoid as best as might be possible for the expression of an ontology of language, encoding biases and ontological commitments. Any of the lexicons that we describe in this paper may be considered in general to definitions or specifications of an ontology. They are all formal descriptions of the concepts of sentiment, wherein a word's sentimental meaning is conceptualized.

A more ambitious system that fits the description of an ontology as provided by Gruber is an upper ontology. An upper ontology is one that hopes to describe the basic types of entities that comprise human discourse. An example of such an upper ontology is the Suggested Upper Merged Ontology, or SUMO \textcolor{gray}{\cite{Niles}}. The goal of SUMO was to link the IEEE-sanctioned Suggested Upper Ontology (SUO) with the English language in general via WordNet. The suggestion of SUMO is that for every synset found in WordNet, that a mapping to a SUO concept be formed. In this system, the core ontological components are both those of WordNet (synsets, relations, et cetera) and the formal concepts from SUO that are mapped to each of the synsets in WordNet. The authors do not describe the process of mapping with much rigor and instead mostly discuss the notation used for the mapping process. The only method to perform the mapping that they make mention of is the utilization of the relations between synsets that might be referred to in information science as synonymity, hypernymy, and instantiation, and using those relations to add to the SUO concept the synset that was being related. The goal is one where the structure and content of SUO might be used to create more structure in WordNet, and the details of WordNet used to create a better SUO. As of this writing, the URL reference in the paper for the SUMO is a dead link and a web search performed using Google's search engine for the Suggested Upper Merged Ontology reveals a very old and seemingly untended website. While it was a valiant effort to describe a complete, upper ontology, it seems to have been outcompeted by methods of informal description such as those that can be found in XML, JSON, and by more formal descriptions such as the Semantic Web and ConceptNet.

Another approach to constructing an ontology that is not as ambitious as an upper ontology or as necessarily complete as WordNet is an ontology such as that of Freebase \textcolor{gray}{\cite{Bollacker}}. Freebase states that it is less rigid than traditional ontologies, but shares in common many of the properties that Gruber describes with his criteria and in his examples. The Freebase data system is structured such that there exist in Freebase entries for different concepts, and while there can be multiple renditions of a given concept, there is the guiding intention in Freebase that conflicting entries be reconciled with each other. This deviates from Gruber's criteria of clarity and coherence in that Freebase allows for ambiguous entries and does not strictly impose a rule of coherency, but it does aspire to such clarity and coherence. Concept entries in Freebase are structured in a way that is none too dissimilar from the concept structure that is used in upper ontologies, though the base concept is merely that of a concept alone without a name to identify specific instances of concepts such as the object or relation concepts that form the core of an upper ontology like SUMO. Instead of being identified by basic types, concepts instead have schemas defined for them by users which then form a type of structuring of knowledge that is similar to the structure provided in systems like SUMO. In this way Freebase is incredibly light in its ontological commitments as such a property is described by Gruber. Similar to SUMO, Freebase seems to have found itself out competed by other methods of structuring knowledge such as those of XML, JSON, ConceptNet, and the Semantic Web. The URL provided in the paper leads to a google developers website emblazoned at the top with a light red text container stating that the project has been decommissioned.

An ontology that seems to have had some staying power is that of ConceptNet \textcolor{gray}{\cite{Liu}}. ConceptNet is an ontology that is based on the principle that much of the meaning of text relies on assumptions of common knowledge. This common knowledge is suggested to include statements such as "a lemon is sour" or "if you forget someone's birthday, they may be unhappy with you", and is suggested to be commonly inferred by human observers of language but very difficult to represent in a manner that can be understood by a machine. Towards this end of identifying common sense knowledge, the authors along with a number of other contributors created the Open Mind Common Sense website, a portal for gathering from human volunteers simple English statements that represent common sense knowledge. The OMCS corpus was generated by providing to the users of the OMCS website 30 different word association or sentence completion tasks of a known form. The forms of these different tasks were such that each task could be understood as representing a certain type of association or relation between a previously identified concept and the information of the association. For example, one of the tasks was to complete statements of the form "\texttt{an apple is <blank>}". Such a task was presumed to represent a type of relation wherein the information provided by the user is predicated of the concept presented to the user, in this case the concept being that which is denoted by the word "apple". For ConceptNet 2.0, OMCS was comprised of 700000 statements generated by 14000 web contributors. Currently OMCS has grown to over 1 million statements generated by 15000 web users \textcolor{gray}{\cite{Arnold}}. From the OMCS corpus, the four syntactic forms of verbs, noun phrases, prepositional phrases, and adjectival phrases were extracted by means of 50 regular expressions. These four syntactic forms were normalized by correcting spelling errors, removing determinant words such as pronouns, removing modal words, and changing verbs to the present tense. These normalized forms were then grouped together to form concepts, the concept representation being a string of words that denoted a concept as it occurred according to certain semantic and syntactic restrictions. Examples from ConceptNet that were generated in this manner are concepts like \texttt{apple}, \texttt{cherry}, \texttt{have nightmare}, \texttt{close eye}, and \texttt{eat food}. Predicates of concepts were also able to be gleaned from the OMCS corpus given the knowledge that each of the statements were of a previously defined structure. These predicates were grouped into 20 relational types that were in turn divided into 8 distinct categories. Relations of interest for sentiment analysis might be those the affective category, which in ConceptNet 2.0 contained the relations of \texttt{MotivationOf} and \texttt{DesireOf}. Relations were then inferred from the established set of concepts and relations by a variety of means. One method of inference was to propagate predicates to concepts that were identified by words which subsumed another word in the WordNet lexicon corresponding to the subsumed concept. Another was to segment the information that was predicated of a concept into its constituent parts, for example an apple described as a round, red object is also assumed to be red provided that a majority of such statements predicated of an apple contain the concept of red. Concepts that were either similar in their usage or morphological derivatives of each other were also related to each other by inferring such relations from resources like WordNet. Included with ConceptNet are a variety of tools that provide a user with an analysis of text according to the text's relation with the concepts of ConceptNet. The most significant of these is the parser referenced as being a natural-language understander, named MontyLingua, which returns the syntactical features of a text which can then be used to directly map the syntactical features to the conceptual representations of ConceptNet. Other functions included in the ConceptNet 2.0 distribution were functions to determine contextual neighborhoods of concepts (IE their relational distances), weighted relations based on domain, topic approximation using contextual neighborhoods, and analogy making using contextual neighborhoods. As an ontology, ConceptNet is best considered as only the network of concepts without these additional functionalities. In this form it meets a fair number of Gruber's criteria for the assessment of ontologies. Notably, ConceptNet seems to have a fair level of clarity, coherence, and extensibility. As ConceptNet stands instantiated, it falls short on encoding bias and ontological commitment but these criteria are less troublesome when ConceptNet is considered as the process for defining concepts instead of ConceptNet in its whole.

The Semantic Web is also a formal structuring of knowledge that has retained some use over the years. It is based on the Web Ontology Language (going by the acronym of OWL), which provides a general set of relations that exist between concepts but does not provide any specification for the content of a concept. The semantic meanings of words are then encoded in OWL. The premise of the Semantic Web is closer to that of an upper ontology than the premise of ConceptNet, but does not appear to subject itself to the requirement of expressing existence in totality. We will not go into the details of the Semantic Web in this paper, but it is worth noting that both ConceptNet and the Semantic Web have mentions made to them in several of the papers that we describe in the following section on ontology supported sentiment analysis.

\section{ONTOLOGY SUPPORTED SENTIMENT ANALYSIS}

Ontology supported sentiment analysis is either an unsupervised or supervised approach to performing sentiment analysis that draws on an exterior body of knowledge as manifest in an ontology like ConceptNet. As they incorporate outside knowledge into the process, ontology supported sentiment analysis approaches are not strictly speaking supervised if a statistical classifier such as SVM (which is described above as supervised) is used as part of the process. Instead, ontology supported sentiment analyses are considered as being either unsupervised or hybrid approaches. We can also create a distinction between the types of ontologies that are utilized to augment sentiment analysis, a distinction between ontologies that are constructed as general purpose ontologies that formalize a wide range of concepts such as ConceptNet and ontologies that are constructed for the specific task at hand. Each of the following examples can be considered in these terms of unsupervised or hybrid, general purpose or specific circumstance ontologies. The main distinction that we choose to focus on is whether a system was developed using a general purpose or specific purpose ontology.

\subsection{Specific purpose ontologies.}
One method of sentiment analysis supported by the construction of an ontology for a specific purpose can be found in Zhou and Chaovalit's "ontology supported polarity mining" or OPSM approach \textcolor{gray}{\cite{Zhou}}. The method is one that considers an ontology for the domain of movie reviews. The process begins with the definition of the ontology for the movie domain as consisting of 30 different subjects of discussion, or concepts, that are often found in movie reviews. These 30 different subjects were then correlated with distinct sections of each of the reviews in a predefined set of 180 movie reviews, and each of these subjects in their distinct sections given a polarity ranking. This manual process of affixing the concepts of the movie ontology to a textual corpus and assigning them polarity scores was performed by two individuals and checked for consistency on 60 movie reviews that were labeled by both individuals. Each section of each movie review was analyzed using both an unsupervised approach and a supervised approach. The unsupervised approach that was used in the paper was a sum of the polarity rankings of each of the words in a given section as defined by the General Inquirer. The supervised approach was two n-gram models that considered each of the segments marked as positive and each of the segments marked as negative, respective. Each section was summed to provide the overall polarity classification of the movie review. These results were compared against the classification of the movie reviews without segmentation according to the concepts of the identified movie ontology, and the comparison showed that a segmentation by concept provided more accurate sentiment polarity classification. Unfortunately, Zhou and Chaovalit's paper does not detail how one might automate the process of splitting a movie review into segments that each represent one unique or distinct concept from their movie ontology.

There are other methods of performing sentiment analysis that are similar to Zhou and Chovalit's OPSM in their use of ontologies. One such methodology can be found in Kontopoulos et at \textcolor{gray}{\cite{Kontopoulos}}. The method described is one that operates on Twitter posts (tweets) and is based on the assumption that ontologies can be constructed that are unique to the intersection between a general textual domain and the tweets that correspond to that general domain. In order to construct such an ontology, the authors suggest the conscription of Formal Concept Analysis and software supported methodologies. Formal Concept Analysis is described as a method of specifying concepts by the objects and attributes that correspond to a concept. A concept such as smart phone would consist of different types of smart phones as the objects, and the attributes would then be the features of each of the different types of smart phones. The software supported methodology suggested is that of OntoGen, which was designed to allow individuals with great knowledge of a given domain but little knowledge of ontological construction the ability to create ontologies from their domain expertise. The output of OntoGen is an ontology that is constructed as a series of nested subconcept relations, where relations were chosen that matched the objects and attributes structure of the output of a Formal Concept Analysis. In both the case of Formal Concept Analysis and the software of OntoGen, a human is required in order to construct the domain and Twitter specific ontology. The ontologies were then expanded by incorporating synonymous or hyponymous terms from WordNet into each of the attributes and each of the objects. Once these ontologies have been constructed, the general sentiment of Twitter users over a given period of time for the given domain is assessed by first finding the set of attributes shared by all objects in the domain, and then querying the Twitter API to find some predetermined number of tweets for each of the attribute and object pairs that occurred. The tweets that were returned from this query were then passed into the OpenDover sentiment analysis software, which provided a sentiment score for each of the respective attribute and object pairs as manifest in the tweet. The sentiment score of an attribute and object pair was then taken as the sum of the scores of each of the respective tweets. The final output was a sentiment score for each of the objects of a domain across each of the attributes shared between all objects of the domain. The example provided considers 4 phone models as compared across their average sentiment scores in regards to their camera, display, battery, and processor. The process was compared to a simple bag of words assessment of Twitter sentiment for a given phone model by combining the sentiment scores of each of the attributes of the given phone model, which revealed that a sentiment analysis that performs its analysis with respect to individual product features is more accurate than a simple bag of words analysis.

A very impressive attempt at creating a purpose specific ontology was made with EmotiNet \textcolor{gray}{\cite{Balahur}}. The authors describe EmotiNet as forming its own emotional ontology, an ontology that is built specifically for the purposes of relating affective concepts to each other. The ontology of emotions initially used in EmotiNet is a combination of the models of Plutchik's wheel of emotion and Parrot's tree-structured listing of emotions. Relations between the different affective categories that were chosen from the two models were were defined, and instances of the affective categories added. To the ontology was added the possibility for affective categories to be related temporally. This emotion ontology was then utilized to label noun-verb-noun triples that were parsed from a portion of the documents from the ISEAR psychological survey. Each of these verb clauses were labeled with one of the emotions of the emotion ontology, and were in turn added to the ontology. Next, documents were clustered by their similarity of their composition as represented by parts of speech, the similarity measure being Lesk distance. Each of the resultant clusters then had a document chosen from it to represent the cluster as a sequence of affects, a temporal representation of emotion. For each of the documents identified action chains were constructed from a series of verb clauses identified in the document, which were then also labeled with one of the emotions of the emotion ontology and added in whole to the EmotiNet emotion ontology. These action chains were constructed by means of identifying temporally relevant words that placed one action clearly before another in the progression of the sampled text and by using this information to order the sequence of verb clauses. The resultant ontology was one that attempted to consider basic emotions (those of the initial ontology), emotions represented as concepts in a manner similar to ConceptNet, and the evolution of emotion over time and the evolution of emotion based on context. The ontology was evaluated against the remaining documents in the ISEAR corpus, and it was observed that of the 895 samples that were tested only 571 could have affective association drawn from EmotiNet. Other test cases were similarly incomplete in their coverage of the ISEAR corpus. Adaption attempts were made to rectify this incomplete coverage. One adaption was to allow for synonymous verbs from the VerbOcean corpus to be adapted, allowing for documents of ISEAR that contained a verb that was synonymous with one of the entries in EmotiNet to be mapped onto EmotiNet. Verbs were also inter-related by means of ConceptNet relations. It also appears that SentiWordNet similarity of individual affective words and verb clusters was employed in order to map some portions of the ISEAR corpus onto EmotiNet. The result of these adaptations was that the coverage increased from 571 of 895 to 625 of 895. In the test best case, wherein adaptations were made but only a portion of the emotions considered, coverage was $79.26\%$. The authors do note that the recall rate of their model was higher than that of other common models, providing evidence that while EmotiNet does not provide complete mappings of textual data it may contain techniques that merit further investigation.

\subsection{General purpose ontologies.}
An early method of ontology supported sentiment analysis that utilized existing ontological resources is that of SenseNet \textcolor{gray}{\cite{AlMasum}}. SenseNet is a system for performing sentiment analysis that considers the base units of sentiment to be verb-subject pairs. A set of verbs from WordNet was labeled as having a polarity score from -5 to 5. Scores were assigned for each of the word-senses present for a word in WordNet, i.e. the multiple uses or senses of the word happy (happy smile, happy situation). The sentiment score for a word was then considered to be the sum of the scores for each sense of a word in proportion to the total number of senses for that word. Scores were provided for words by several individuals, and the average of these scores were the score ultimately assigned to each verb. Concepts from ConceptNet were then assigned polarity scores between -5 and 5. Concepts were chosen from ConceptNet on for their relative positions in ConceptNet; the more subsumed concepts a concept had, the more likely it was to be chosen for the assignment of a sentiment score. Documents were then parsed by a language parser, Machinese Syntax, whose output was then used to create tuples of the form actor-verb-subject, where verbs mapped to verbs of WordNet and subjects mapped to concepts from ConceptNet. Where concepts in these tuples did not have sentiment scores, a sentiment score was created based on either a related concept that did have a score, or by the sum of the sentiment scores of verbs that correspond to actions that are pertinent to the concept in ConceptNet. These tuples were then scored by the relative scores of their components; a negative verb and a positive concept yielded a negative polarity, a negative verb and negative concept yielded a positive polarity, a positive verb and a positive concept yielded a positive polarity, and a positive verb and a negative concept yielded a negative polarity. A number of other rules also considered the modifying value of adverbs and adjectives as well as the modifying value of negation. The system was determined to have an ability to classify news documents according to negative or positive sentiment with 90\% accuracy.

A slightly more modern method of ontology supported sentiment analysis utilizing existing resources is presented in Mukherjee and Joshi's 2013 paper \textcolor{gray}{\cite{Mukherjee}}. Their approach is to draw on the ConceptNet ontology to improve sentiment polarity classification by considering consumer reviews as represented by a set of concepts drawn from ConceptNet. It is a process that can be utilized to create a domain-specific ontology in a computational manner without the requirement of human labeling of that domain-specific ontology. This is done by constructing an ontology tree, which is a tree of ConceptNet concepts. An ontology tree is constructed by first extracting the concepts of a given portion of text by mapping each of the nouns of that portion of text to their corresponding ConceptNet concepts. Next, these concepts are added to the list of potential concepts of the ontology tree if their frequency of occurrence in the text relative to the occurrence of all concepts in the text is above some certain threshold. The root of the tree is initially considered as the domain name of the text, which may be arbitrarily chosen in the absence of human labeling. Each of the concepts are then added to the tree by according their relations in ConceptNet which are considered to fall into the 3 distinct categories of hierarchical relations, synonymous relations, and functional relations. Concepts with hierarchical relations are added to the tree first, then concepts that are synonymous have their nodes in the tree merged, and lastly the concepts connected by functional relationships are added. Each of these concepts are classified according to the majority vote of the sentiment score of words that are associated with it by means of clustering of words according to their relative distance from the noun that the concept represents. The sentiment scores of each word were determined by the Bing Liu lexicon. The score of each concept is then considered as the sum of the scores of each of its children relative to their depth in the constructed ontology tree. The method of performing polarity classification with an ontology tree was compared with polarity classification that used only ConceptNet mappings by clustering of words as well as a classification performed using the sum of the sentiment scores for each word of the document as determined by the Bing Liu sentiment lexicon. The comparison showed that the use of an ontology tree outperformed all other methods for the domains of automobile, camera, and software reviews.

One very interesting and modern method of performing ontology supported sentiment analysis is SenticNet \textcolor{gray}{\cite{CambriaSpeer,CambriaHavasi,CambriaOlsher,CambriaPoria}}. SenticNet is based on two primary assumptions: that emotion can be adequately described as the product of multiple affects as in Plutchik's hourglass model of emotion, and that concepts that have affective content can be generalized given both their relations to other concepts and their affective content. Towards this end, the authors develop AffectiveSpace, which is itself an extension of both ConceptNet and WordNet-Affect \textcolor{gray}{\cite{CambriaFu}}. Some of the papers refer to AffectNet, which is presumably an extension of WordNet-Affect. AffectiveSpace is constructed by assigning the affective words of WordNet-Affect to concepts in ConceptNet and ranking each of the affects in each concept for an initial set of affectively defined concepts. The affective values of these defined concepts were propagated into the rest of ConceptNet for those concepts that were connected by certain relations. The assignment of affect values to new concepts was defined to diminish the contribution of defined concepts the further a concept was away from a defined concept, with distance measured by the number of concepts traveled through in order to arrive at the new concept. These affective properties were taken along with the relations possible in ConceptNet and formed into a vector to describe the semantic and sentic components of a concept. From this vector a subset of the affective attributes and relations were chosen as the principle components of all concepts with affective content. These vectors were then taken as the coordinates of the concept in an AffectiveSpace, which was later simplified to be the relative angles and distances between concepts from a "neutral" origin, these angles and distances being defined as the Euclidean metric on the vectors of attributes. Some of the concepts in AffectiveSpace coincide with the affects of Plutchik's hourglass of emotions, wherein it is assumed that emotional states can be described by the relative excitement or depression of four distinct physiological systems of the mind. These four distinct dimensions of emotion each have six levels of activation, creating 24 distinct emotional categories which are presumed to be able to be combined in some composition to describe the full scope of human emotion. Each of these 24 distinct emotional categories are mapped in AffectiveSpace by their corresponding ConceptNet concepts, and the sentiment content of each concept in AffectiveSpace is then generalized into one level for each of the four emotional dimensions of the where the level of a given dimension for a given a concept is determined by closest of the six concepts belonging to each dimension. AffectiveSpace may then be used to perform a polarity classification based on the sum of the different dimensions of each concept.

Initially AffectiveSpace was used to perform sentiment polarity classification by considering a document as a bag of concepts, where the text of a document was parsed into concepts by a semantic parser of a nondescript nature and then the sum of the sentiment scores for each concept considered \textcolor{gray}{\cite{CambriaSpeer}}. Later, a previous body of work that identified certain patterns of concepts that occur in sentiment bearing texts was utilized to form more precise classification of sentiment, wherein the authors describe the sentiment as flowing between concepts \textcolor{gray}{\cite{CambriaPoria}}. Modifications to the original structure of SenticNet were made that aimed to improve the quality of affective categorization of concepts.

In SenticNet 2, the domain of a given portion of text was considered along side the other data of the text \textcolor{gray}{\cite{CambriaHavasi}}. In SenticNet 2, the affective labels in AffectiveSpace were propagated through ConceptNet only for those concepts that were considered to be relevant to a given domain. The relevancy of a concept was determined by the relative occurrence of a concept in an identified domain and the occurrence of a concept in the whole of the training corpus.

SenticNet 3 deviated from the original specification of the core of AffectiveSpace being ConceptNet concepts and instead utilized the COGBASE and INTELNET ontologies to represent concepts \textcolor{gray}{\cite{CambriaOlsher}}. The ontologies of COGBASE and INTELNET utilize activations of certain sets of different affective fragments to describe concepts, where an affective concept was considered to be the transition of given textual units from one affective fragment to another. This was presumed to model associative memory in humans, and the affective fragments were attributed as concepts to other concepts that were constructed in a similar way from different conceptual fragments. The fragments were drawn from the corpus that builds into ConceptNet, the data of WordNet-Affect, and several other sources. In this way the fragment activation model captured the details present in the previous conceptual modelings used in AffectiveSpace. The mapping of this instance of AffectiveSpace was also done relative to the hourglass model of human emotion, and sentiment polarity classification performed by both a bag of concepts model as well as a sentic flow model.

SenticNet 5 dropped this standard and reverted back to the utilization of an updated ConceptNet \textcolor{gray}{\cite{CambriaPoria}}. The major development of SenticNet 5 is the integration of the advancements that have been made in neural networks into the structuring of AffectiveSpace. Neural networks were used to generalize the concepts of ConceptNet based on the contexts in which the words that correspond to ConceptNet concepts occurred in a corpus. The idea is to reduce concepts into clusters of concepts that are referred to as primitive concepts. For example, \texttt{munch\_toast} and \texttt{slurp\_noodles} are considered to be instances of the conceptual primitive \texttt{EAT\_FOOD}. These conceptual primitives were determined to have affective values equal to the average of the affective values of all concepts that fell under the given conceptual primitive. Given that these conceptual primitives were determined by their contextual similarity, it was possible to identify using the same measures of contextual similarity concepts that otherwise eluded AffectiveSpace prior to the utilization of neural networks for concept identification. These concepts that had no explicit affective content were then assigned affective values equal to the affective values of the primitive concept they were identified to belong to. Primitive concepts are in SenticNet 5 one of three levels of representation available, the other two being the representation of text as the concepts of AffectiveSpace and the other being a set of entities identified by their relevant subsuming concepts via the IsA relation of ConceptNet. SenticNet 5 performs sentiment classification of text from movie reviews with $92.8\%$ accuracy and represents the state of the art in ontology supported sentiment analysis.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{CONCLUDING REMARKS}

Computational sentiment analysis is an area of study that is evidenced by the body of academic publications to be very active. Its applications have been demonstrated to be helpful to both institutions and individuals. There are many different approaches to performing computational sentiment analysis, and this study focused on those approaches that explicitly drew upon human knowledge in order to improve the process of analysis. We have described these approaches as ontologically supported sentiment analysis, or if we are being consistent in our language, ontologically supported computational sentiment analysis. Many of these approaches implicitly or explicitly assume that human sentiment can be expressed through the psychological theory of appraisal. These approaches have proven to be effective, and do not even begin to address the full richness of data that is becoming available with the continued growth and development of the web \textcolor{gray}{\cite{CambriaSchuller}}.

We might note as we did in the introduction that an attempt to characterize sentiment is an attempt at performing a task that is as of yet uncomputable, intractable in the terms of the information and computational sciences. While attempts made towards this end have not succeeded, they have made substantial gains in terms of their ability to more completely represent in a precise manner that which remains for some human ineffable. These are attempts that have focused either on a representation of the whole of human emotion and human knowledge and invariably fallen flat, or attempts that have been more practical in their methodology. Of those attempts that have not found themselves lost in the sands of time, the most effective tend to be those that retain a respect for the esoteric nature of human emotion as affect by refraining from placing themselves too far from the symbolic and linguistic representation of emotion that is being analyzed. WordNet has proven to be an incredible resource that sticks directly to the lexical representation of words. ConceptNet has proven to be a reliable ontology as it does not attempt to create an upper ontology but instead creates an ontology from fragments of lexical representations. SenticNet appears to have promise by refraining from an attempt to classify in full human emotion, instead opting to utilize consistent application of psychological theory to create representations of the components of such theory. Other systems of knowledge representation such as OPSM find success by greatly restricting their purview, focusing on small regions of human understanding which might be leveraged for the purposes of an analysis of sentiment. It would seem then that respect for the absolute wonder that is the complexity, expressivity, and immensity of human language is essential in finding success in natural language processing (which Chomsky's writings seem to never fail in illuminating to us).

Computational sentiment analysis is an area of study that seems to be bearing fruit and is fecundated by support from the traditional AI concepts of ontology. While it seems unwise to presume that the intersection of disciplines that is sentiment analysis combined with informatic ontologies might provide a computable representation of the fullness that is human emotion, it does seem at least practical to consider the positive consequence brought about by attempts to leverage traditional methods on modern approaches. There are many struggles remaining in the attempt to make emotion and sentiment more computable, and many more potential solutions to the difficulties presented by a problem of such complexity are likely to arise. Sentiment analysis, as perceived as a sub-discipline of natural language processing, is far from dead and is even farther from being a solved problem.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{ACKNOWLEDGMENT}
Thank you Professor Steinmetz for having read this and for having routinely provided the support and encouragement necessary for myself to really begin grappling with the challenging topics and ideas that comprise advanced areas of study, beyond what is typically considered to be undergraduate study.

I might also thank Professor Crockett for having pushed me to start thinking more critically of the world around me, and for having helped to reveal to me the more subtle nuances that might be said to be found in academic studies. One might call this an appreciation for the social and human component of an academic enterprise, and of life in general.

I remain indebted to you both.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% There are something like 700 words in the bibliography.
\begin{thebibliography}{99}

\bibitem{AlMasum} S.M. Al Masum, H. Prendinger, M. Ishizuka. SenseNet: A linguistic tool to visualize numerical-valence based sentiment of textual data. Proceedings of the 2007 International Conference on Natural Language Processing, pages 147-152. (2007).

\bibitem{Arnold} K. Arnold, R. Speer, D. Clark. Open Mind Common Sense. MIT Media Lab. Retrieved 21 December 2017 from https://github.com/commonsense/omcs. (2009).

\bibitem{Baccianella} S. Baccianella, A. Esuli, F. Sebastiani. SENTIWORDNET 3.0: an enhanced lexical resource for sentiment analysis and opinion mining. Proceedings of the Ninth Conference on Language Resources and Evaluation, Malta, pages 2200-2204. (2010).

\bibitem{Balahur} A. Balahur, J. Hermida, A. Montoyo. Building and exploiting EmotiNet, a knowledge base for emotion detection based on the appraisal theory model. IEEE Transactions on Affective Computing, volume 3, issue 1, pages 88-101. (2012).

\bibitem{Blei} D. Blei, A. Ng, M. Jordan. Latent Dirichlet Allocation. Journal of Machine Learning Research, volume 3, pages 993-1022. (2003).

\bibitem{Bollacker} K. Bollacker, C. Evans, P. Paritosh, T. Surge, J. Taylor. FreeBase: a collaboratively created graph database for structuring human knowledge. Proceedings of the 2008 ACM SIGMOD international conference on Management of Data, pages 1247-1250. (2008).

\bibitem{Buvac} V. Buvac, P. Stone. The General Inquirer User's Guide. Retrieved 15 Dec 2017 from http://www.wjh.harvard.edu/\~inquirer/j1\_0/manual /manual.html. (2001).

\bibitem{CambriaHavasi} E. Cambria, C. Havasi, A. Hussain. SenticNet 2: a semantic and affective resource for opinion mining and sentiment analysis. Proceedings of the 25th International Florida Artificial Intelligence Research Society Conference, pages 202-207. (2012).

\bibitem{CambriaFu} E. Cambria, J. Fu, F. Bisio, S. Poria. AffectiveSpace 2: Enabling affective intuition for concept-level sentiment analysis. Proceedings of the AAAI Twenty-Ninth Conference on Artificial Intelligence, Austin, pages 508-514. (2015).

\bibitem{CambriaOlsher} E. Cambria, D. Olsher, D. Rajagopal. SenticNet 3: a common and common-sense knowledge base for cognition-driven sentiment analysis. Proceedings of the AAAI Twenty-eighth Conference on Artificial Intelligence, pages 1515-1521. (2014).

\bibitem{CambriaPoria} E. Cambria, S. Poria, D. Hazarika, K. Kwok. SenticNet 5: Discovering Conceptual Primitives for Sentiment Analysis by Means of Context Embeddings. Association for the Advancement of Artificial Intelligence, prepublication. (2018).

\bibitem{CambriaSchuller} E. Cambria, B. Schuller, Y. Xia, C. Havasi. New Avenues in Opinion Mining and Sentiment Analysis. IEEE Intelligent Systems, volume 28, number 2, pages 15-21. (2013).

\bibitem{CambriaSpeer} E. Cambria, R. Speer, C. Havasi, A. Hussain. SenticNet: a publicly available semantic resource for opinion mining. 2010 AAAI Fall Symposium: Commonsense Knowledge, volume 10, issue 2, pages 14-19. (2010).

\bibitem{Chomsky} N. Chomsky. Three Models for the Description of Language. IRE Transactions on Information Theory, volume 3, number 3, pages 113-124. (1956).

\bibitem{Esuli} A. Esuli, F. Sebastiani. SENITWORDNET: a publicly available lexical resource for opinion mining. Proceedings of the 5th Conference on Language Resources and Evaluation, Genoa, pages 417-422. (2006).

\bibitem{WordNet} C. Fellbaum, editor. Wordnet: An Electronic Lexical Database. MIT Press. (1998).

\bibitem{Griffiths} T. Griffiths, M. Steyvers, J. Tenenbaum. Topics in Semantic Representation. American Psychological Association: Psychological Review, volume 114, number 2, pages 211-244. (2007).

\bibitem{Gruber} T.R. Gruber. Toward principles for the design of ontologies used for knowledge sharing? International Journal of Human-Computer Studies, volume 43, issues 5-6, pages 907-928. (1995).

\bibitem{Kontopoulos} E. Kontopoulos, C. Berberidis, T. Dergiades, N. Bassiliades. Ontology-based sentiment analysis of twitter posts. Expert Systems with Applications, volume 40, pages 4065-4074. (2013).

\bibitem{Liu} H. Liu, P. Singh. ConceptNet - a pratical commonsense reasoning toolkit. BT Technology Journal, volume 22, issue 4, pages 211-227. (2004).

\bibitem{Manning} C. Manning, P. Raghavan, H Schutze. Introduction to Information Retrieval, HTML edition. Cambridge University Press. Retrieved 17 December 2017 from https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html. (2008).

\bibitem{Mukherjee} S. Mukherjee, S. Joshi. Sentiment aggregation using ConceptNet ontology. International Joint Conference on Natural Language Processing, pages 570-578. (2013).

\bibitem{Neviarouskaya} A. Neviarouskaya, H. Prendinger, M. Ishizuka. SentiFul: a lexicon for sentiment analysis. IEEE Transactions on Affective Computing, volume 2, issue 1, pages 22-36. (2011).

\bibitem{Niles} I. Niles, A. Pease. Linking lexicons and ontologies: mapping WordNet to the suggested upper merged ontology. Proceedings of the 2003 International Conference on Information and Knowledge, Las Vegas, pages 23-26. (2003).

\bibitem{PangLee} B. Pang, L. Lee. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, volume 2, numbers 1-2, pages 1-137. (2008).

\bibitem{RaviRavi} K. Ravi, V. Ravi. A survey on opinion mining and sentiment analysis: Tasks, approaches, and applications. Knowledge Based-Systems, volume 89, pages 14-46. (2015).

\bibitem{Strapparava} C. Strapparava, A. Valitutti. WordNet-Affect: an affective extension of WordNet. Proceeding of LREC, volume 4, pages 1083-1086. (2004).

\bibitem{Zhou} L. Zhou, P. Chaovalit. Ontology-supported polarity mining. Journal of the American Society for Information Science and Technology, volume 59, issue 1, pages 98-110. (2008).

\end{thebibliography}

\end{document}
